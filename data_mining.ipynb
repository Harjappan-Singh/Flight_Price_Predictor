{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flight Price Prediction Data Mining\n",
    "\n",
    "**Objective**: Extract flight prices and relevant information from Kayak for dates between **10th October 2024 to 10th January 2025** from **Dublin Airport to London Heathrow Airport** for **1 adult passenger**, **economy**, **one-way flights**.\n",
    "\n",
    "This notebook outlines the process for data extraction, issues encountered, and their solutions, as well as the relevant variables mined for the dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scenario\n",
    "\n",
    "The aim is to collect data from `kayak.ie` to predict flight prices for different dates and times. \n",
    "\n",
    "**Scope**:\n",
    "- Flights from Dublin to London Heathrow Airport\n",
    "- Flights between 10th October 2024 and 10th January 2025\n",
    "- For 1 adult passenger\n",
    "- Economy class\n",
    "- One-way flights\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extraction Variables\n",
    "\n",
    "The following variables will be extracted:\n",
    "\n",
    "1. **Date** -> Categorical\n",
    "2. **Flight Name** -> Categorical\n",
    "3. **Stops** -> Numerical\n",
    "4. **Price** -> Numerical\n",
    "5. **Duration** -> Numerical\n",
    "6. **Departure Time** -> Categorical\n",
    "7. **Arrival Time** -> Categorical\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping Logic\n",
    "\n",
    "The following block of code performs web scraping to extract flight data from `kayak.ie` over multiple dates.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#used sleep() for few seconds in order to not be detected as a bot\n",
    "# Fxn to scrape flight data for a given month\n",
    "def scrape_flights_for_month(start_date, end_date):\n",
    "    driver = webdriver.Chrome()\n",
    "    \n",
    "    flight_details = []\n",
    "    current_date = start_date\n",
    "\n",
    "    while current_date <= end_date:\n",
    "\n",
    "        formatted_date = current_date.strftime('%Y-%m-%d')\n",
    "        url = f'https://www.kayak.ie/flights/DUB-LHR/{formatted_date}?sort=bestflight_a'\n",
    "        \n",
    "        driver.get(url)\n",
    "        \n",
    "        # Pause to allow the page to load [Sleep for 4 seconds]\n",
    "        time.sleep(10) \n",
    "        \n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        \n",
    "        flight_containers = soup.findAll('div', class_=\"yuAt yuAt-pres-rounded yuAt-mod-box-shadow\")\n",
    "        for item in flight_containers:\n",
    "            try:\n",
    "                flight_name = item.find('div', class_=\"J0g6-operator-text\").get_text(strip=True)\n",
    "                stops = item.find('span', class_=\"JWEO-stops-text\").get_text(strip=True)\n",
    "                price = item.find('div', class_=\"f8F1-price-text\").get_text(strip=True)\n",
    "                \n",
    "                #Extracting duration by skipping time and stops\n",
    "                duration = None\n",
    "                divs = item.findAll('div', class_=\"vmXl vmXl-mod-variant-default\")\n",
    "\n",
    "                for div in divs:\n",
    "                    if not div.find('span'):  # If there are no spans inside the div, it's most likely the duration\n",
    "                        duration = div.get_text(strip=True)\n",
    "                        break\n",
    "\n",
    "                times_div = item.find('div', class_=\"vmXl vmXl-mod-variant-large\")\n",
    "                if times_div:\n",
    "                    times = times_div.get_text(strip=True).split(\"â€“\")\n",
    "                    departure_time = times[0].strip() if len(times) > 0 else \"Departure not found\"\n",
    "                    arrival_time = times[1].strip() if len(times) > 1 else \"Arrival not found\"\n",
    "                else:\n",
    "                    departure_time, arrival_time = \"Departure not found\", \"Arrival not found\"\n",
    "\n",
    "                flight_details.append([formatted_date, flight_name, stops, price, duration, departure_time, arrival_time])\n",
    "            except Exception as e:\n",
    "                print(f\"Error extracting data: {e}\")\n",
    "        \n",
    "        current_date += timedelta(days=1)\n",
    "\n",
    "    driver.quit()\n",
    "    return flight_details\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "start_date = datetime(2024, 10, 10)\n",
    "end_date = datetime(2024, 11, 9)\n",
    "\n",
    "all_flight_details = []\n",
    "\n",
    "while start_date <= datetime(2025, 1, 10):\n",
    "    #print(f\"Scraping flights from {start_date.strftime('%Y-%m-%d')} to {end_date.strftime('%Y-%m-%d')}\")\n",
    "    monthly_flights = scrape_flights_for_month(start_date, end_date)\n",
    "    \n",
    "    all_flight_details.extend(monthly_flights)\n",
    "    \n",
    "    start_date = end_date + timedelta(days=1)\n",
    "    end_date = start_date + timedelta(days=30)\n",
    "    \n",
    "    # Sleep for 5 seconds to avoid bot detection\n",
    "    time.sleep(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Storing Data into CSV\n",
    "\n",
    "After data is collected for the flight details, it's important to store them in a CSV format for further analysis and cleaning. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flight details have been written to flight_details.csv\n"
     ]
    }
   ],
   "source": [
    "csv_file_name = 'flight_details.csv'\n",
    "\n",
    "header = ['Date', 'Flight Name', 'Stops', 'Price', 'Duration', 'Departure-Time', 'Arrival-Time']\n",
    "\n",
    "with open(csv_file_name, mode='w', newline='') as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    writer.writerow(header)\n",
    "    writer.writerows(all_flight_details)\n",
    "\n",
    "print(f\"Flight details have been written to {csv_file_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Issues Faced\n",
    "\n",
    "1. **Multiple Elements Sharing the Same Class**: \n",
    "   - Problem: Elements with class `vmXl vmXl-mod-variant-default` are shared between different sections (departure time, duration, stops).\n",
    "   - **Solution**: Inspected further child elements like `<span>` or `<div>` within those classes to correctly extract data.\n",
    "\n",
    "2. **Website Blocking (Captcha)**: \n",
    "   - Problem: After multiple consecutive requests, the website prompts a captcha.\n",
    "   - **Solution**: Introduced a sleep mechanism to limit requests and prevent detection. Also restarted the driver after scraping for one month.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comments\n",
    "\n",
    "- `+1` in flight arrival time indicates that the flight lands the next day.\n",
    "- The data stored in CSV format can be used for further cleaning and analysis in Pandas or other tools.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
